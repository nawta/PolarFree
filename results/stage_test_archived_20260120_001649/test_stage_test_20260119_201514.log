2026-01-19 20:15:14,608 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.4.2
	PyTorch: 2.11.0.dev20260118+cu128
	TorchVision: 0.25.0.dev20260118+cu128
2026-01-19 20:15:14,609 INFO: 
  name: stage_test
  model_type: PolarFree_S2
  scale: 1
  num_gpu: 1
  manual_seed: 100
  datasets:[
    val:[
      name: ValSet
      type: PairedImagePolarDataset
      dataroot_gt: polargb/test
      dataroot_lq: polargb/test
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      test_scenes: ['00', '01', '02', '03', '04', '05', '06', '07']
      phase: val
      scale: 1
    ]
  ]
  network_g:[
    type: Transformer
    inp_channels: 3
    out_channels: 3
    dim: 48
    num_blocks: [3, 4, 4, 4]
    num_refinement_blocks: 4
    heads: [1, 2, 4, 8]
    ffn_expansion_factor: 2.66
    bias: False
    LayerNorm_type: WithBias
    dual_pixel_task: False
    embed_dim: 64
    group: 4
  ]
  network_le:[
    type: latent_encoder_gelu
    in_chans: 12
    embed_dim: 64
    block_num: 6
    group: 4
    stage: 1
    patch_expansion: 0.5
    channel_expansion: 4
  ]
  network_le_dm:[
    type: latent_encoder_gelu
    in_chans: 9
    embed_dim: 64
    block_num: 6
    group: 4
    stage: 2
    patch_expansion: 0.5
    channel_expansion: 4
  ]
  network_d:[
    type: denoising
    in_channel: 256
    out_channel: 256
    inner_channel: 512
    block_num: 4
    group: 4
    patch_expansion: 0.5
    channel_expansion: 2
  ]
  diffusion_schedule:[
    apply_ldm: False
    schedule: linear
    timesteps: 8
    linear_start: 0.1
    linear_end: 0.99
  ]
  path:[
    pretrain_network_g: ./pretrained/net_g_latest.pth
    param_key_g: params
    strict_load_g: True
    pretrain_network_le: None
    strict_load_le: True
    pretrain_network_le_dm: ./pretrained/net_le_dm_latest.pth
    strict_load_le_dm: True
    pretrain_network_d: ./pretrained/net_d_latest.pth
    strict_load_d: True
    resume_state: None
    results_root: /home/naoto/workspace/PolarFree/results/stage_test
    log: /home/naoto/workspace/PolarFree/results/stage_test
    visualization: /home/naoto/workspace/PolarFree/results/stage_test/visualization
  ]
  train:[
    total_iter: 1
    warmup_iter: -1
    use_grad_clip: True
    scheduler:[
      type: CosineAnnealingRestartCyclicLR
      periods: [100000, 200000]
      restart_weights: [1, 1]
      eta_mins: [0.0002, 1e-06]
    ]
    mixing_augs:[
      mixup: False
      mixup_beta: 1.2
      use_identity: True
    ]
    optim_total:[
      type: AdamW
      lr: 2e-10
      weight_decay: 0.0001
      betas: [0.9, 0.999]
    ]
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
    tv_opt:[
      loss_weight: 0.0005
    ]
    vgg_opt:[
      loss_weight: 0.02
    ]
    pixel_diff_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
    phase_opt:[
      loss_weight: 0.1
    ]
  ]
  val:[
    val_freq: 1.0
    suffix: None
    save_img: False
    pbar: True
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 0
        test_y_channel: False
      ]
    ]
  ]
  logger:[
    print_freq: 1
    save_checkpoint_freq: 4000.0
    use_tb_logger: False
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: False

2026-01-19 20:15:14,610 INFO: Dataset [PairedImagePolarDataset] - ValSet is built.
2026-01-19 20:15:14,610 INFO: Number of images in test dataset ValSet: 188
2026-01-19 20:15:14,616 INFO: Network [latent_encoder_gelu] is created.
2026-01-19 20:15:14,622 INFO: Network: latent_encoder_gelu, with parameters: 640,984
2026-01-19 20:15:14,622 INFO: latent_encoder_gelu(
  (pixel_unshuffle): PixelUnshuffle(downscale_factor=4)
  (conv1): Sequential(
    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): GELU(approximate='none')
  )
  (blocks): ModuleList(
    (0-5): 6 x Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): GELU(approximate='none')
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): AdaptiveAvgPool2d(output_size=(4, 4))
  (mlp): MLP(
    (patch_mixer): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8, out_features=16, bias=True)
    )
    (channel_mixer): Sequential(
      (0): Linear(in_features=64, out_features=256, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=256, out_features=64, bias=True)
    )
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (end): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): GELU(approximate='none')
  )
)
2026-01-19 20:15:14,626 INFO: Network [latent_encoder_gelu] is created.
2026-01-19 20:15:14,632 INFO: Network: latent_encoder_gelu, with parameters: 613,336
2026-01-19 20:15:14,632 INFO: latent_encoder_gelu(
  (pixel_unshuffle): PixelUnshuffle(downscale_factor=4)
  (conv1): Sequential(
    (0): Conv2d(144, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): GELU(approximate='none')
  )
  (blocks): ModuleList(
    (0-5): 6 x Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): GELU(approximate='none')
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): AdaptiveAvgPool2d(output_size=(4, 4))
  (mlp): MLP(
    (patch_mixer): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8, out_features=16, bias=True)
    )
    (channel_mixer): Sequential(
      (0): Linear(in_features=64, out_features=256, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=256, out_features=64, bias=True)
    )
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (end): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): GELU(approximate='none')
  )
)
2026-01-19 20:15:14,644 INFO: Network [denoising] is created.
2026-01-19 20:15:14,651 INFO: Network: denoising, with parameters: 2,629,937
2026-01-19 20:15:14,651 INFO: denoising(
  (first_layer): Sequential(
    (0): Linear(in_features=768, out_features=512, bias=True)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (blocks): ModuleList(
    (0-1): 2 x Sequential(
      (0): MLP(
        (patch_mixer): Sequential(
          (0): Linear(in_features=16, out_features=8, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=8, out_features=16, bias=True)
        )
        (channel_mixer): Sequential(
          (0): Linear(in_features=512, out_features=1024, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): GELU(approximate='none')
    )
  )
  (final_layer): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): GELU(approximate='none')
  )
)
2026-01-19 20:15:14,753 INFO: Network [Transformer] is created.
2026-01-19 20:15:14,828 INFO: Network: Transformer, with parameters: 18,855,655
2026-01-19 20:15:14,828 INFO: Transformer(
  (down_1): Sequential(
    (0): Rearrange('b n c -> b c n')
    (1): Linear(in_features=16, out_features=4, bias=True)
    (2): Rearrange('b c n -> b n c')
    (3): Linear(in_features=256, out_features=256, bias=True)
  )
  (down_2): Sequential(
    (0): Rearrange('b n c -> b c n')
    (1): Linear(in_features=4, out_features=1, bias=True)
    (2): Rearrange('b c n -> b n c')
    (3): Linear(in_features=256, out_features=256, bias=True)
  )
  (patch_embed): OverlapPatchEmbed(
    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (encoder_level1): BasicLayer(
    (blocks): ModuleList(
      (0-2): 3 x TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
          (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)
          (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (him): HIM(
      (norm1): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (norm2): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (q): Linear(in_features=48, out_features=48, bias=False)
      (kv): Linear(in_features=256, out_features=96, bias=False)
      (proj): Linear(in_features=48, out_features=48, bias=True)
    )
  )
  (down1_2): Downsample(
    (body): Sequential(
      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (encoder_level2): BasicLayer(
    (blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
          (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)
          (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (him): HIM(
      (norm1): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (norm2): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (q): Linear(in_features=96, out_features=96, bias=False)
      (kv): Linear(in_features=256, out_features=192, bias=False)
      (proj): Linear(in_features=96, out_features=96, bias=True)
    )
  )
  (down2_3): Downsample(
    (body): Sequential(
      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (encoder_level3): BasicLayer(
    (blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)
          (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (him): HIM(
      (norm1): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (norm2): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (q): Linear(in_features=192, out_features=192, bias=False)
      (kv): Linear(in_features=256, out_features=384, bias=False)
      (proj): Linear(in_features=192, out_features=192, bias=True)
    )
  )
  (down3_4): Downsample(
    (body): Sequential(
      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelUnshuffle(downscale_factor=2)
    )
  )
  (latent): BasicLayer(
    (blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
          (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (ln1): Linear(in_features=256, out_features=384, bias=True)
          (ln2): Linear(in_features=256, out_features=384, bias=True)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)
          (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (ln1): Linear(in_features=256, out_features=384, bias=True)
          (ln2): Linear(in_features=256, out_features=384, bias=True)
        )
      )
    )
  )
  (up4_3): Upsample(
    (body): Sequential(
      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (decoder_level3): BasicLayer(
    (blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)
          (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (him): HIM(
      (norm1): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (norm2): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (q): Linear(in_features=192, out_features=192, bias=False)
      (kv): Linear(in_features=256, out_features=384, bias=False)
      (proj): Linear(in_features=192, out_features=192, bias=True)
    )
  )
  (up3_2): Upsample(
    (body): Sequential(
      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (decoder_level2): BasicLayer(
    (blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
          (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)
          (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (him): HIM(
      (norm1): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (norm2): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (q): Linear(in_features=96, out_features=96, bias=False)
      (kv): Linear(in_features=256, out_features=192, bias=False)
      (proj): Linear(in_features=96, out_features=96, bias=True)
    )
  )
  (up2_1): Upsample(
    (body): Sequential(
      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): PixelShuffle(upscale_factor=2)
    )
  )
  (decoder_level1): BasicLayer(
    (blocks): ModuleList(
      (0-2): 3 x TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
          (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)
          (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (him): HIM(
      (norm1): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (norm2): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (q): Linear(in_features=96, out_features=96, bias=False)
      (kv): Linear(in_features=256, out_features=192, bias=False)
      (proj): Linear(in_features=96, out_features=96, bias=True)
    )
  )
  (refinement): BasicLayer(
    (blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
          (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)
          (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (him): HIM(
      (norm1): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (norm2): LayerNorm_Without_Shape(
        (body): WithBias_LayerNorm()
      )
      (q): Linear(in_features=96, out_features=96, bias=False)
      (kv): Linear(in_features=256, out_features=192, bias=False)
      (proj): Linear(in_features=96, out_features=96, bias=True)
    )
  )
  (output): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
)
2026-01-19 20:15:14,834 INFO: Loading latent_encoder_gelu model from ./pretrained/net_le_dm_latest.pth, with param key: [params].
2026-01-19 20:15:14,848 INFO: Loading denoising model from ./pretrained/net_d_latest.pth, with param key: [params].
2026-01-19 20:15:15,017 INFO: Loading Transformer model from ./pretrained/net_g_latest.pth, with param key: [params].
2026-01-19 20:15:15,116 INFO: Model [PolarFree_S2] is created.
2026-01-19 20:15:15,116 INFO: Starting testing on ValSet...
2026-01-19 20:18:55,797 INFO: Validation ValSet
	 # psnr: 22.4428	Best: 22.4428 @ 0 iter

2026-01-19 20:18:55,810 INFO: Finished testing on ValSet!
2026-01-19 20:18:55,810 INFO: All testing finished!
